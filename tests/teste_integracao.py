#!/usr/bin/env python3
"""
Script de Teste de Integra√ß√£o Completo
=====================================

Este script testa se o pipeline completo est√° funcionando ap√≥s os refinamentos.

Autor: Yan
Data: 2025-01-27
"""

import os
import sys
import json
import pandas as pd
import numpy as np
import joblib
import logging
from datetime import datetime

# Adicionar o diret√≥rio src ao path
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'src'))

# Configura√ß√£o do logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_project_root():
    """Retorna o diret√≥rio raiz do projeto"""
    return os.path.dirname(os.path.dirname(__file__))

def carregar_configuracao():
    """Carrega configura√ß√µes do config.json"""
    try:
        config_path = os.path.join(get_project_root(), 'config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        logger.info("‚úÖ Config.json carregado com sucesso")
        return config
    except Exception as e:
        logger.error(f"‚ùå Erro ao carregar config.json: {e}")
        return None

def verificar_dados():
    """Verifica se os dados est√£o dispon√≠veis"""
    resultados = {}
    project_root = get_project_root()
    
    # Dados brutos
    dados_brutos_path = os.path.join(project_root, 'dados_brutos')
    dados_brutos = len([f for f in os.listdir(dados_brutos_path) if f.endswith('.csv')])
    resultados['dados_brutos'] = dados_brutos
    logger.info(f"‚úÖ Dados brutos: {dados_brutos} arquivos")
    
    # Dados processados
    dados_processados_path = os.path.join(project_root, 'dados_processados')
    dados_processados = len([f for f in os.listdir(dados_processados_path) if f.endswith('.csv')])
    resultados['dados_processados'] = dados_processados
    logger.info(f"‚úÖ Dados processados: {dados_processados} arquivos")
    
    # Modelos
    models_path = os.path.join(project_root, 'models')
    modelos = len([f for f in os.listdir(models_path) if f.endswith('.joblib')])
    resultados['modelos'] = modelos
    logger.info(f"‚úÖ Modelos treinados: {modelos} arquivos")
    
    return resultados

def testar_carregamento_modelo():
    """Testa carregamento e estrutura dos modelos"""
    project_root = get_project_root()
    models_path = os.path.join(project_root, 'models')
    modelos = [f for f in os.listdir(models_path) if f.endswith('.joblib')]
    
    if not modelos:
        logger.error("‚ùå Nenhum modelo encontrado")
        return False
    
    try:
        # Testar primeiro modelo
        modelo_file = modelos[0]
        logger.info(f"üîç Testando modelo: {modelo_file}")
        
        modelo_path = os.path.join(models_path, modelo_file)
        modelo_data = joblib.load(modelo_path)
        
        # Verificar estrutura esperada
        required_keys = ['modelo', 'feature_names', 'metricas', 'config']
        missing_keys = [key for key in required_keys if key not in modelo_data]
        
        if missing_keys:
            logger.warning(f"‚ö†Ô∏è Chaves faltando no modelo: {missing_keys}")
        else:
            logger.info("‚úÖ Estrutura do modelo OK")
        
        # Testar predi√ß√£o b√°sica
        modelo = modelo_data['modelo']
        feature_names = modelo_data.get('feature_names', [])
        
        logger.info(f"‚úÖ Modelo: {type(modelo).__name__}")
        logger.info(f"‚úÖ Features: {len(feature_names)} vari√°veis")
        
        # Teste de predi√ß√£o com dados dummy
        if feature_names:
            dummy_data = np.random.random((1, len(feature_names)))
            pred = modelo.predict(dummy_data)
            prob = modelo.predict_proba(dummy_data)
            logger.info(f"‚úÖ Predi√ß√£o teste: {pred[0]}, confian√ßa: {max(prob[0]):.3f}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao testar modelo: {e}")
        return False

def testar_dados_processados():
    """Testa carregamento dos dados processados"""
    try:
        project_root = get_project_root()
        dados_path = os.path.join(project_root, 'dados_processados')
        arquivos = [f for f in os.listdir(dados_path) if f.endswith('_processed.csv')]
        
        if not arquivos:
            logger.error("‚ùå Nenhum dado processado encontrado")
            return False
        
        # Testar primeiro arquivo
        arquivo = arquivos[0]
        logger.info(f"üîç Testando dados: {arquivo}")
        
        arquivo_path = os.path.join(dados_path, arquivo)
        df = pd.read_csv(arquivo_path, index_col=0, parse_dates=True)
        
        logger.info(f"‚úÖ Dados carregados: {len(df)} registros")
        logger.info(f"‚úÖ Colunas: {len(df.columns)} vari√°veis")
        logger.info(f"‚úÖ Per√≠odo: {df.index[0]} a {df.index[-1]}")
        
        # Verificar se h√° features essenciais
        features_essenciais = ['Close', 'Open', 'High', 'Low', 'Volume']
        features_encontradas = [f for f in features_essenciais if f in df.columns]
        logger.info(f"‚úÖ Features OHLCV: {len(features_encontradas)}/5")
        
        # Verificar indicadores t√©cnicos
        indicadores = ['RSI', 'MACD', 'SMA_20', 'SMA_50', 'ATR']
        indicadores_encontrados = [i for i in indicadores if i in df.columns]
        logger.info(f"‚úÖ Indicadores t√©cnicos: {len(indicadores_encontrados)}/{len(indicadores)}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao testar dados: {e}")
        return False

def simular_backtest_simples():
    """Simula um backtest b√°sico sem depend√™ncias complexas"""
    try:
        logger.info("üîç Simulando backtest b√°sico...")
        
        project_root = get_project_root()
        models_path = os.path.join(project_root, 'models')
        dados_path = os.path.join(project_root, 'dados_processados')
        
        # Carregar um modelo
        modelos = [f for f in os.listdir(models_path) if f.endswith('.joblib')]
        if not modelos:
            logger.error("‚ùå Nenhum modelo para teste")
            return False
        
        modelo_file = modelos[0]
        modelo_path = os.path.join(models_path, modelo_file)
        modelo_data = joblib.load(modelo_path)
        modelo = modelo_data['modelo']
        feature_names = modelo_data.get('feature_names', [])
        
        # Carregar dados correspondentes
        nome_modelo = modelo_file.replace('modelo_', '').replace('.joblib', '')
        arquivo_dados = os.path.join(dados_path, f'{nome_modelo}_processed.csv')
        
        if not os.path.exists(arquivo_dados):
            logger.error(f"‚ùå Dados n√£o encontrados: {arquivo_dados}")
            return False
        
        df = pd.read_csv(arquivo_dados, index_col=0, parse_dates=True)
        
        # Simular algumas predi√ß√µes
        if feature_names and len(feature_names) <= len(df.columns):
            logger.info("‚úÖ Simulando predi√ß√µes...")
            
            # Pegar √∫ltimos 10 registros
            df_test = df.tail(10)
            
            # Tentar fazer predi√ß√µes com features dispon√≠veis
            available_features = [f for f in feature_names if f in df_test.columns]
            
            if len(available_features) >= len(feature_names) * 0.8:  # Pelo menos 80% das features
                # Preencher features faltantes com 0
                features_completas = []
                for feature in feature_names:
                    if feature in df_test.columns:
                        features_completas.append(feature)
                    else:
                        df_test[feature] = 0
                        features_completas.append(feature)
                
                X_test = df_test[feature_names].fillna(0).values
                
                predictions = modelo.predict(X_test)
                probabilities = modelo.predict_proba(X_test)
                
                logger.info(f"‚úÖ Predi√ß√µes realizadas: {len(predictions)} sinais")
                logger.info(f"‚úÖ Distribui√ß√£o: {dict(zip(*np.unique(predictions, return_counts=True)))}")
                logger.info(f"‚úÖ Confian√ßa m√©dia: {np.mean([max(p) for p in probabilities]):.3f}")
                
                # Verificar se h√° sinais de compra/venda
                sinais_compra = sum(predictions == 1)
                sinais_venda = sum(predictions == -1)
                logger.info(f"‚úÖ Sinais: {sinais_compra} compras, {sinais_venda} vendas")
                
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Poucas features compat√≠veis: {len(available_features)}/{len(feature_names)}")
        
        return False
        
    except Exception as e:
        logger.error(f"‚ùå Erro na simula√ß√£o: {e}")
        return False

def testar_importacao_modulos():
    """Testa se os m√≥dulos do projeto podem ser importados"""
    try:
        logger.info("üîç Testando importa√ß√£o dos m√≥dulos...")
        
        # Testar importa√ß√£o dos principais m√≥dulos
        modulos_testados = 0
        modulos_ok = 0
        
        try:
            import coleta_dados
            logger.info("‚úÖ coleta_dados importado")
            modulos_ok += 1
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Erro ao importar coleta_dados: {e}")
        modulos_testados += 1
        
        try:
            import preprocessamento
            logger.info("‚úÖ preprocessamento importado")
            modulos_ok += 1
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Erro ao importar preprocessamento: {e}")
        modulos_testados += 1
        
        try:
            import treinamento_modelo
            logger.info("‚úÖ treinamento_modelo importado")
            modulos_ok += 1
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Erro ao importar treinamento_modelo: {e}")
        modulos_testados += 1
        
        try:
            import backtest_engine
            logger.info("‚úÖ backtest_engine importado")
            modulos_ok += 1
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Erro ao importar backtest_engine: {e}")
        modulos_testados += 1
        
        try:
            import analise_resultados
            logger.info("‚úÖ analise_resultados importado")
            modulos_ok += 1
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Erro ao importar analise_resultados: {e}")
        modulos_testados += 1
        
        logger.info(f"‚úÖ M√≥dulos importados: {modulos_ok}/{modulos_testados}")
        return modulos_ok == modulos_testados
        
    except Exception as e:
        logger.error(f"‚ùå Erro no teste de importa√ß√£o: {e}")
        return False

def executar_pipeline_mini():
    """Executa uma vers√£o mini do pipeline para testar integra√ß√£o"""
    try:
        logger.info("üîç Executando mini pipeline de integra√ß√£o...")
        
        project_root = get_project_root()
        
        # 1. Verificar se h√° dados para processar
        dados_path = os.path.join(project_root, 'dados_brutos')
        arquivos_dados = [f for f in os.listdir(dados_path) if f.endswith('.csv')][:2]  # Pegar s√≥ 2 arquivos
        
        if not arquivos_dados:
            logger.error("‚ùå Nenhum dado bruto dispon√≠vel")
            return False
        
        logger.info(f"‚úÖ Testando com {len(arquivos_dados)} arquivos de dados")
        
        # 2. Verificar modelos
        models_path = os.path.join(project_root, 'models')
        modelos = [f for f in os.listdir(models_path) if f.endswith('.joblib')]
        
        if not modelos:
            logger.error("‚ùå Nenhum modelo dispon√≠vel")
            return False
        
        logger.info(f"‚úÖ {len(modelos)} modelos dispon√≠veis")
        
        # 3. Testar carregamento e predi√ß√£o
        for modelo_file in modelos[:2]:  # Testar s√≥ 2 modelos
            try:
                modelo_path = os.path.join(models_path, modelo_file)
                modelo_data = joblib.load(modelo_path)
                
                ativo = modelo_file.replace('modelo_', '').replace('.joblib', '')
                logger.info(f"‚úÖ Modelo {ativo} carregado com sucesso")
                
                # Simular predi√ß√£o
                feature_names = modelo_data.get('feature_names', [])
                if feature_names:
                    dummy_data = np.random.random((5, len(feature_names)))
                    modelo = modelo_data['modelo']
                    pred = modelo.predict(dummy_data)
                    logger.info(f"‚úÖ {ativo}: {len(pred)} predi√ß√µes simuladas")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao testar modelo {modelo_file}: {e}")
        
        logger.info("‚úÖ Mini pipeline executado com sucesso")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro no mini pipeline: {e}")
        return False

def gerar_relatorio_integracao():
    """Gera relat√≥rio de integra√ß√£o do sistema"""
    logger.info("=" * 70)
    logger.info("RELAT√ìRIO DE INTEGRA√á√ÉO P√ìS-REFINAMENTOS")
    logger.info("=" * 70)
    
    inicio = datetime.now()
    
    # Testar componentes
    resultados = {
        'config': carregar_configuracao() is not None,
        'dados': verificar_dados(),
        'modelos': testar_carregamento_modelo(),
        'dados_processados': testar_dados_processados(),
        'importacao_modulos': testar_importacao_modulos(),
        'backtest_simples': simular_backtest_simples(),
        'mini_pipeline': executar_pipeline_mini()
    }
    
    # Resumo
    logger.info("")
    logger.info("üìä RESUMO DOS TESTES:")
    logger.info(f"‚úÖ Configura√ß√£o: {'OK' if resultados['config'] else 'ERRO'}")
    logger.info(f"‚úÖ Modelos: {'OK' if resultados['modelos'] else 'ERRO'}")
    logger.info(f"‚úÖ Dados Processados: {'OK' if resultados['dados_processados'] else 'ERRO'}")
    logger.info(f"‚úÖ Importa√ß√£o M√≥dulos: {'OK' if resultados['importacao_modulos'] else 'ERRO'}")
    logger.info(f"‚úÖ Simula√ß√£o Backtest: {'OK' if resultados['backtest_simples'] else 'ERRO'}")
    logger.info(f"‚úÖ Mini Pipeline: {'OK' if resultados['mini_pipeline'] else 'ERRO'}")
    
    # Status geral
    testes_ok = sum([
        resultados['config'],
        resultados['modelos'], 
        resultados['dados_processados'],
        resultados['importacao_modulos'],
        resultados['backtest_simples'],
        resultados['mini_pipeline']
    ])
    total_testes = 6
    
    logger.info("")
    logger.info(f"üéØ STATUS GERAL: {testes_ok}/{total_testes} testes passaram ({testes_ok/total_testes*100:.1f}%)")
    
    if testes_ok == total_testes:
        logger.info("üéâ SISTEMA TOTALMENTE INTEGRADO E FUNCIONAL!")
        logger.info("üöÄ Pronto para execu√ß√£o completa do pipeline")
    elif testes_ok >= total_testes * 0.8:
        logger.info("‚úÖ Sistema majoritariamente funcional com pequenos ajustes necess√°rios")
    else:
        logger.info("‚ö†Ô∏è Alguns componentes importantes precisam de aten√ß√£o")
    
    fim = datetime.now()
    logger.info(f"‚è∞ Teste conclu√≠do em: {fim - inicio}")
    logger.info("=" * 70)
    
    return resultados

def main():
    """Fun√ß√£o principal do teste de integra√ß√£o"""
    logger.info("üéØ TESTE DE INTEGRA√á√ÉO DO SISTEMA REFINADO")
    resultados = gerar_relatorio_integracao()
    
    # Sugest√µes baseadas nos resultados
    if not all(resultados[key] for key in ['config', 'modelos', 'dados_processados']):
        logger.info("")
        logger.info("üí° SUGEST√ïES DE MELHORIAS:")
        
        if not resultados['config']:
            logger.info("- Verificar o arquivo config.json")
        if not resultados['modelos']:
            logger.info("- Executar treinamento de modelos")
        if not resultados['dados_processados']:
            logger.info("- Executar preprocessamento dos dados")
    
    return resultados

if __name__ == "__main__":
    main()
